digraph {
	graph [size="12,12"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	140627315412400 [label="
 (128, 1)" fillcolor=darkolivegreen1]
	140627318626240 [label=AddmmBackward0]
	140627318625808 -> 140627318626240
	140627632462560 [label="layer_out.bias
 (1)" fillcolor=lightblue]
	140627632462560 -> 140627318625808
	140627318625808 [label=AccumulateGrad]
	140627318626912 -> 140627318626240
	140627318626912 [label=NativeBatchNormBackward0]
	140627318276352 -> 140627318626912
	140627318276352 [label=ReluBackward0]
	140627318278560 -> 140627318276352
	140627318278560 [label=AddmmBackward0]
	140627318278080 -> 140627318278560
	140627632460880 [label="layer_2.bias
 (64)" fillcolor=lightblue]
	140627632460880 -> 140627318278080
	140627318278080 [label=AccumulateGrad]
	140627318279472 -> 140627318278560
	140627318279472 [label=NativeBatchNormBackward0]
	140627318276880 -> 140627318279472
	140627318276880 [label=ReluBackward0]
	140627318277792 -> 140627318276880
	140627318277792 [label=AddmmBackward0]
	140627318280048 -> 140627318277792
	140627315412560 [label="layer_1.bias
 (64)" fillcolor=lightblue]
	140627315412560 -> 140627318280048
	140627318280048 [label=AccumulateGrad]
	140627318276208 -> 140627318277792
	140627318276208 [label=TBackward0]
	140627318279520 -> 140627318276208
	140627315412480 [label="layer_1.weight
 (64, 10)" fillcolor=lightblue]
	140627315412480 -> 140627318279520
	140627318279520 [label=AccumulateGrad]
	140627318277024 -> 140627318279472
	140627632463200 [label="batchnorm1.weight
 (64)" fillcolor=lightblue]
	140627632463200 -> 140627318277024
	140627318277024 [label=AccumulateGrad]
	140627318278128 -> 140627318279472
	140627632463360 [label="batchnorm1.bias
 (64)" fillcolor=lightblue]
	140627632463360 -> 140627318278128
	140627318278128 [label=AccumulateGrad]
	140627318279568 -> 140627318278560
	140627318279568 [label=TBackward0]
	140627318277840 -> 140627318279568
	140628103105248 [label="layer_2.weight
 (64, 64)" fillcolor=lightblue]
	140628103105248 -> 140627318277840
	140627318277840 [label=AccumulateGrad]
	140627318278608 -> 140627318626912
	140627632463120 [label="batchnorm2.weight
 (64)" fillcolor=lightblue]
	140627632463120 -> 140627318278608
	140627318278608 [label=AccumulateGrad]
	140627318276256 -> 140627318626912
	140627632461680 [label="batchnorm2.bias
 (64)" fillcolor=lightblue]
	140627632461680 -> 140627318276256
	140627318276256 [label=AccumulateGrad]
	140627318626768 -> 140627318626240
	140627318626768 [label=TBackward0]
	140627318276688 -> 140627318626768
	140627632777472 [label="layer_out.weight
 (1, 64)" fillcolor=lightblue]
	140627632777472 -> 140627318276688
	140627318276688 [label=AccumulateGrad]
	140627318626240 -> 140627315412400
}
